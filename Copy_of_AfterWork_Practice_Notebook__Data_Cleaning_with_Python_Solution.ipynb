{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AfterWork Practice Notebook_ Data Cleaning with Python - Solution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "AdqLGpdH_867",
        "8tAUAu98l-E6",
        "o39LEL0PmKJa",
        "BMXTATeJmOGX",
        "2gjU-yrmmo8I",
        "OWcy51lCOuTv",
        "ONPG_rNpOuT8",
        "zgSTFXdcOuUc",
        "ebaricL9O20B",
        "WWZ0GCbCO20L",
        "XXsiMoefO21J",
        "UQvS83K_PBJh",
        "CjklXwZLPBJw",
        "o8VZ3JLQPBJy",
        "qP7c_QZcPBK0",
        "vudHxVsePBLA",
        "_7MfKNGePLVE",
        "tSyyvcJJPLVO",
        "gWiBc-smPLVS",
        "B_mlBg-TPLVe",
        "vbVkgj0VPLWh",
        "v5M3iGK8PZ3Y",
        "jnxNSUhdPZ3u",
        "0Z92GZUgPZ35",
        "wt8Se1hXPZ4C"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manj1/Data-Science/blob/master/Copy_of_AfterWork_Practice_Notebook__Data_Cleaning_with_Python_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKX9LrWlN5ME",
        "colab_type": "text"
      },
      "source": [
        "<font color=\"blue\">To use this notebook on Colaboratory, you will need to make a copy of it. Go to File > Save a Copy in Drive. You can then use the new copy that will appear in the new tab.</font>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XzGFitQl60K",
        "colab_type": "text"
      },
      "source": [
        "# AfterWork Practice Notebook: Data Cleaning with Python - Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdqLGpdH_867",
        "colab_type": "text"
      },
      "source": [
        "#### <font color=\"blue\">Pre-requisites</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzG_vFPsAF9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-requisite 1\n",
        "# ---\n",
        "# Importing pandas library\n",
        "# ---\n",
        "# -> This is a data analysis and manipulation library with Python.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "import pandas as pd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxs3j_OJQ7my",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-requisite 2\n",
        "# ---\n",
        "# Importing the numpy library\n",
        "# -> This is a library for scientific computing with Python.\n",
        "# -> It simply allows us to perfom complex mathematical operations.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tAUAu98l-E6",
        "colab_type": "text"
      },
      "source": [
        "## 1. Standardisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o39LEL0PmKJa",
        "colab_type": "text"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMXTATeJmOGX",
        "colab_type": "text"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql23JRMAlvv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "10566d41-be50-435b-cae0-a6a77359ddaa"
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# Renaming column names\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# Reading our dataset from the url\n",
        "# ---\n",
        "# We also specify the character ; as our separator\n",
        "# ---\n",
        "# \n",
        "df = pd.read_csv('account_dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>NAME</th>\n",
              "      <th>CITY</th>\n",
              "      <th>COUNTRY</th>\n",
              "      <th>HEIGHT</th>\n",
              "      <th>WEIGHT</th>\n",
              "      <th>ACCOUNT A</th>\n",
              "      <th>ACCOUNT B</th>\n",
              "      <th>TOTAL ACCOUNT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Adi Dako</td>\n",
              "      <td>LISBON</td>\n",
              "      <td>PORTUGAL</td>\n",
              "      <td>56</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>4340</td>\n",
              "      <td>6730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>John Paul</td>\n",
              "      <td>LONDON</td>\n",
              "      <td>UNITED KINGDOM</td>\n",
              "      <td>62</td>\n",
              "      <td>165.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34334</td>\n",
              "      <td>38834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Cindy Jules</td>\n",
              "      <td>Stockholm</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>48</td>\n",
              "      <td>117.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5504</td>\n",
              "      <td>8949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Arthur Kegels</td>\n",
              "      <td>BRUSSELS</td>\n",
              "      <td>BELGIUM</td>\n",
              "      <td>59</td>\n",
              "      <td>121.0</td>\n",
              "      <td>4344.0</td>\n",
              "      <td>8999</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Freya Bismark</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>GERMANYY</td>\n",
              "      <td>53</td>\n",
              "      <td>126.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>19000</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0               NAME  ... ACCOUNT B TOTAL ACCOUNT\n",
              "0           0          Adi Dako   ...      4340          6730\n",
              "1           1          John Paul  ...     34334         38834\n",
              "2           2        Cindy Jules  ...      5504          8949\n",
              "3           3      Arthur Kegels  ...      8999           300\n",
              "4           4      Freya Bismark  ...     19000         26000\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbZr_6MXhLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "921d1972-34bf-4f5c-ff0c-c49dbd3f74cb"
      },
      "source": [
        "# Example 1a\n",
        "# --- \n",
        "# In this example, we will renaming our columns, if we have many column names.\n",
        "# We will use the str.strip(), str.lower(), str.replace() functions \n",
        "# to ensure that our column names are in lowercase format that easily can work with.\n",
        "# ---\n",
        "# str.strip() - We use this function to remove leading and trailing characters.\n",
        "# str.lower() - This function converts all characters to lowercase\n",
        "# str.replace() - This functions is used replace text with some other text.\n",
        "# ---\n",
        "#\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n",
        "\n",
        "# Then preview our dataframe\n",
        "# ---\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>account_a</th>\n",
              "      <th>account_b</th>\n",
              "      <th>total_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adi Dako</td>\n",
              "      <td>LISBON</td>\n",
              "      <td>PORTUGAL</td>\n",
              "      <td>56</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>4340</td>\n",
              "      <td>6730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Paul</td>\n",
              "      <td>LONDON</td>\n",
              "      <td>UNITED KINGDOM</td>\n",
              "      <td>62</td>\n",
              "      <td>165.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34334</td>\n",
              "      <td>38834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cindy Jules</td>\n",
              "      <td>Stockholm</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>48</td>\n",
              "      <td>117.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5504</td>\n",
              "      <td>8949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arthur Kegels</td>\n",
              "      <td>BRUSSELS</td>\n",
              "      <td>BELGIUM</td>\n",
              "      <td>59</td>\n",
              "      <td>121.0</td>\n",
              "      <td>4344.0</td>\n",
              "      <td>8999</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Freya Bismark</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>GERMANYY</td>\n",
              "      <td>53</td>\n",
              "      <td>126.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>19000</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name        city  ... account_b  total_account\n",
              "0          Adi Dako   LISBON      ...      4340           6730\n",
              "1          John Paul   LONDON     ...     34334          38834\n",
              "2        Cindy Jules   Stockholm  ...      5504           8949\n",
              "3      Arthur Kegels    BRUSSELS  ...      8999            300\n",
              "4      Freya Bismark      Berlin  ...     19000          26000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcZ63_4lWDRG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "24e62ff8-7768-49d6-935f-56d50fe88a93"
      },
      "source": [
        "# Example 1b\n",
        "# ---\n",
        "# Alternatively we can renaming column names in a dataframe manually by \n",
        "# specifying the column names that we would like to have. \n",
        "# Unfortunately this method becomes cumbersome when the no. of variables increase.\n",
        "# ---\n",
        "#\n",
        "\n",
        "# We will reloading our dataset again for this example and replace our dataframe\n",
        "# with a new dataframe.\n",
        "# ---\n",
        "# \n",
        "df = pd.read_csv('http://bit.ly/DataCleaningDataset', ';') \n",
        "\n",
        "# We then specifying our columns names, store them in a list, then afterwards\n",
        "# assign the list to the column labels. By doing this, we replace the original\n",
        "# columns with our column names stored in the list.\n",
        "# ---\n",
        "# \n",
        "df.columns = ['name', 'city', 'country', 'height', 'weight', 'account_a', 'account_b', 'total_account']\n",
        "\n",
        "# We the preview our dataframe as shown \n",
        "# ---\n",
        "#\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>account_a</th>\n",
              "      <th>account_b</th>\n",
              "      <th>total_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adi Dako</td>\n",
              "      <td>LISBON</td>\n",
              "      <td>PORTUGAL</td>\n",
              "      <td>56</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>4340</td>\n",
              "      <td>6730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Paul</td>\n",
              "      <td>LONDON</td>\n",
              "      <td>UNITED KINGDOM</td>\n",
              "      <td>62</td>\n",
              "      <td>165.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34334</td>\n",
              "      <td>38834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cindy Jules</td>\n",
              "      <td>Stockholm</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>48</td>\n",
              "      <td>117.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5504</td>\n",
              "      <td>8949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arthur Kegels</td>\n",
              "      <td>BRUSSELS</td>\n",
              "      <td>BELGIUM</td>\n",
              "      <td>59</td>\n",
              "      <td>121.0</td>\n",
              "      <td>4344.0</td>\n",
              "      <td>8999</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Freya Bismark</td>\n",
              "      <td>Berlin</td>\n",
              "      <td>GERMANYY</td>\n",
              "      <td>53</td>\n",
              "      <td>126.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>19000</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name        city  ... account_b  total_account\n",
              "0          Adi Dako   LISBON      ...      4340           6730\n",
              "1          John Paul   LONDON     ...     34334          38834\n",
              "2        Cindy Jules   Stockholm  ...      5504           8949\n",
              "3      Arthur Kegels    BRUSSELS  ...      8999            300\n",
              "4      Freya Bismark      Berlin  ...     19000          26000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "59SR9Kap7gMj"
      },
      "source": [
        "##### <font color=\"blue\">Example 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g_2_fG1md0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "58169a5f-cce3-4de0-962f-c30496b2c065"
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# During standardisation, we can also perform string conversion. \n",
        "# In this example, we will convert the values of the column city to lower case values.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# Lets convert the city column to comprise of only lowercase characters\n",
        "# ---\n",
        "# \n",
        "df['city'] = df['city'].str.lower()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>account_a</th>\n",
              "      <th>account_b</th>\n",
              "      <th>total_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adi Dako</td>\n",
              "      <td>lisbon</td>\n",
              "      <td>PORTUGAL</td>\n",
              "      <td>56</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>4340</td>\n",
              "      <td>6730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Paul</td>\n",
              "      <td>london</td>\n",
              "      <td>UNITED KINGDOM</td>\n",
              "      <td>62</td>\n",
              "      <td>165.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34334</td>\n",
              "      <td>38834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cindy Jules</td>\n",
              "      <td>stockholm</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>48</td>\n",
              "      <td>117.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5504</td>\n",
              "      <td>8949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arthur Kegels</td>\n",
              "      <td>brussels</td>\n",
              "      <td>BELGIUM</td>\n",
              "      <td>59</td>\n",
              "      <td>121.0</td>\n",
              "      <td>4344.0</td>\n",
              "      <td>8999</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Freya Bismark</td>\n",
              "      <td>berlin</td>\n",
              "      <td>GERMANYY</td>\n",
              "      <td>53</td>\n",
              "      <td>126.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>19000</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name        city  ... account_b  total_account\n",
              "0          Adi Dako   lisbon      ...      4340           6730\n",
              "1          John Paul   london     ...     34334          38834\n",
              "2        Cindy Jules   stockholm  ...      5504           8949\n",
              "3      Arthur Kegels    brussels  ...      8999            300\n",
              "4      Freya Bismark      berlin  ...     19000          26000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WCk6jJA-7cpm"
      },
      "source": [
        "##### <font color=\"blue\">Example 3</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F8bgFBh2JAs3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "07679145-6013-48dc-e0b3-3928e97d5f95"
      },
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# We can also perform types of conversion that we would want i.e. metric conversion.\n",
        "# In this example, we will convert our height values to centimeters noting \n",
        "# that 1 inch = 2.54 cm.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# \n",
        "\n",
        "# We perform our conversion across the column that we would want \n",
        "# then replace the column with the outcome of our conversion.\n",
        "# ---\n",
        "#\n",
        "df['height'] = df['height'] * 2.54\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>account_a</th>\n",
              "      <th>account_b</th>\n",
              "      <th>total_account</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Adi Dako</td>\n",
              "      <td>lisbon</td>\n",
              "      <td>PORTUGAL</td>\n",
              "      <td>142.24</td>\n",
              "      <td>132.0</td>\n",
              "      <td>2390.0</td>\n",
              "      <td>4340</td>\n",
              "      <td>6730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>John Paul</td>\n",
              "      <td>london</td>\n",
              "      <td>UNITED KINGDOM</td>\n",
              "      <td>157.48</td>\n",
              "      <td>165.0</td>\n",
              "      <td>4500.0</td>\n",
              "      <td>34334</td>\n",
              "      <td>38834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cindy Jules</td>\n",
              "      <td>stockholm</td>\n",
              "      <td>Sweden</td>\n",
              "      <td>121.92</td>\n",
              "      <td>117.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5504</td>\n",
              "      <td>8949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Arthur Kegels</td>\n",
              "      <td>brussels</td>\n",
              "      <td>BELGIUM</td>\n",
              "      <td>149.86</td>\n",
              "      <td>121.0</td>\n",
              "      <td>4344.0</td>\n",
              "      <td>8999</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Freya Bismark</td>\n",
              "      <td>berlin</td>\n",
              "      <td>GERMANYY</td>\n",
              "      <td>134.62</td>\n",
              "      <td>126.0</td>\n",
              "      <td>7000.0</td>\n",
              "      <td>19000</td>\n",
              "      <td>26000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                name        city  ... account_b  total_account\n",
              "0          Adi Dako   lisbon      ...      4340           6730\n",
              "1          John Paul   london     ...     34334          38834\n",
              "2        Cindy Jules   stockholm  ...      5504           8949\n",
              "3      Arthur Kegels    brussels  ...      8999            300\n",
              "4      Freya Bismark      berlin  ...     19000          26000\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F76wMqtH7Z6W"
      },
      "source": [
        "##### <font color=\"blue\">Example 4</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7xqz-EHilp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "a9b9f8f8-5ec1-4c91-8a5e-325984c247c1"
      },
      "source": [
        "# Example 4\n",
        "# ---\n",
        "# We can also perform other types of conversion such as datatype conversion as shown\n",
        "# ---\n",
        "\n",
        "\n",
        "# Let's first determine the column/feature datatypes\n",
        "# ---\n",
        "# \n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name              object\n",
              "city              object\n",
              "country           object\n",
              "height           float64\n",
              "weight           float64\n",
              "account_a        float64\n",
              "account_b          int64\n",
              "total_account      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVwcfVsfjW7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "add92b85-c2a2-4542-f48b-7e703a1c4401"
      },
      "source": [
        "# Then perform a conversion by converting our column/feature \n",
        "# through the use of the apply() function, passing the numerical \n",
        "# type provided by numpy.\n",
        "# To get an understanding of other datatypes provided by numpy we can visit: \n",
        "# https://docs.scipy.org/doc/numpy/user/basics.types.html\n",
        "# ---\n",
        "# Other \n",
        "# ---\n",
        "# \n",
        "df['height'] = df['height'].apply(np.int64)\n",
        "\n",
        "# Let's now check whether our conversion happened by check our updated datatypes\n",
        "# ---\n",
        "# \n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "name              object\n",
              "city              object\n",
              "country           object\n",
              "height             int64\n",
              "weight           float64\n",
              "account_a        float64\n",
              "account_b          int64\n",
              "total_account      int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gjU-yrmmo8I",
        "colab_type": "text"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M81HSax-W3-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Convert the variables account_a and account_b to float datatype.\n",
        "# ---\n",
        "# Hint: You can refer to the dataset in the example.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSLJ97Uc8YAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['account_a'] = df['account_a'].apply(np.float64)\n",
        "df['account_b'] = df['account_b'].apply(np.float64)\n",
        "\n",
        "# Confirming our conversion\n",
        "# ---\n",
        "# \n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGSOBG7im9Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Convert the given weight feature in the dataset from pounds to kgs. \n",
        "# ---\n",
        "# Hint: 1 pound = 0.453592 kgs\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2oHImT_-c_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['weight'] = df['weight'] * 0.453592\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zMMfEWlzI_6C",
        "colab": {}
      },
      "source": [
        "# Challenge 3\n",
        "# ---\n",
        "# Question: Rename the columns in the following dataset.\n",
        "# ---\n",
        "# Hint: Remember to use a different dataframe name other than df i.e. gv_df\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/GVProjectsFunding\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU2Qr1vf-WuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our dataset \n",
        "# ---\n",
        "# \n",
        "gv_df = pd.read_csv('http://bit.ly/GVProjectsFunding')\n",
        "gv_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky-yObrd-YuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Renaming our columns\n",
        "# ---\n",
        "# \n",
        "gv_df.columns = gv_df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('_-', '_').str.replace('__', '_').str.replace('(', '').str.replace(')', '')\n",
        "gv_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OWcy51lCOuTv"
      },
      "source": [
        "## 2. Syntax Errors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ONPG_rNpOuT8"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JBVRXQvY7WEB"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6JgjmQlAOuUA",
        "colab": {}
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# While performing our analysis, we can get to a point where we need to \n",
        "# fix spelling mistakes or typos. This example will show us how we can \n",
        "# go about this.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# Let's replacing any value \"GERMANYY\" with the correct value \"GERMANY\".\n",
        "# We use the string replace() function to perform our operation as shown.\n",
        "# ---\n",
        "# \n",
        "df['country'] = df['country'].str.replace('GERMANYY', 'GERMANY')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0ZXm4a9V7VFq"
      },
      "source": [
        "##### <font color=\"blue\">Example 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cViv8asNOuUM",
        "colab": {}
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# We can also decide to strip or remove leading spaces (space infront) \n",
        "# and trailing spaces (spaces at the end) by using the string strip() function\n",
        "# covered in this example.\n",
        "# ---\n",
        "# Dataset = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# We first load our dataframe column with the intention to observing leading \n",
        "# and trailing spaces in the city column\n",
        "# ---\n",
        "# \n",
        "df['city']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6hu9lJXnpPs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then later we strip the leading and trailing spaces as shown and lastly \n",
        "# confirm our changes  \n",
        "# ---\n",
        "# \n",
        "df['city'] = df['city'].str.strip()\n",
        "df['city']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zgSTFXdcOuUc"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N7vIG505OuUo",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Deal with the leading and trailing whitespaces from Name \n",
        "# and Team variables in the following dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/NBABasketballDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Gwa1VKl_SmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Getting all our columns\n",
        "# ---\n",
        "# \n",
        "nba_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtFfW2qJ_o5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stripping the leading and trailing spaces\n",
        "# ---\n",
        "# \n",
        "# Stripping the leading and trailing spaces\n",
        "# ---\n",
        "# \n",
        "nba_df['Name'] = nba_df['Name'].str.strip() \n",
        "nba_df['Team'] = nba_df['Team'].str.strip()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aS00dbYkOuUu",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Fix the spelling errors in the Team variable where it states \"oston Celtics\" to \"Boston Celtics\"\n",
        "# ---\n",
        "# Hint: To solve this challenge, you can perform two steps i.e. \n",
        "# Step 1: Replace \"oston Celtics\" with \"Boston Celtics\"\n",
        "# Step 2: Replace \"BBoston Celtics\" with \"Boston Celtics\"\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/NBABasketballDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCl2i770_YI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading our dataset\n",
        "# ---\n",
        "# \n",
        "nba_df = pd.read_csv('http://bit.ly/NBABasketballDataset')\n",
        "nba_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVKtP6D4_htj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First step\n",
        "# ---\n",
        "# \n",
        "nba_df['Team'] = nba_df['Team'].str.replace('oston Celtics', 'Boston Celtics')\n",
        "nba_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F59r95ZV_jle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Second step\n",
        "# ---\n",
        "# \n",
        "nba_df['Team'] = nba_df['Team'].str.replace('BBoston Celtics', 'Boston Celtics')\n",
        "nba_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ebaricL9O20B"
      },
      "source": [
        "## 3. Irrelevant Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WWZ0GCbCO20L"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bjflp2aF7SUB"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cTzUuFAyO20Q",
        "colab": {}
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# We can also deleting/dropping irrelevant columns/features. \n",
        "# By irrelevant we mean dataset features that we don't need \n",
        "# to answer a research question. \n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oiYYzezq4Wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting an Irrelevant Column i.e. if we didn't require the column city \n",
        "# to answer our research question.\n",
        "# ---\n",
        "# While dropping/deleting those two columns:\n",
        "# a) We set axis = 1\n",
        "#    A dataframe has two axes: “axis 0” and “axis 1”. \n",
        "#    “axis 0” represents rows and “axis 1” represents columns.\n",
        "# b) We can also set Inplace = True.\n",
        "#    This means the changes would be made to the original dataframe.\n",
        "# Dropping the irrelevant columns i.e. Team and Weight\n",
        "# Those values were dropped since axis was set equal to 1 and \n",
        "# the changes were made in the original data frame since inplace was True.\n",
        "# \n",
        "df.drop([\"city\"], axis = 1, inplace = True) \n",
        " \n",
        "# And preview our resulting dataset\n",
        "# ---\n",
        "# \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naAOHnkNsz-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can drop multiple columns as shown\n",
        "# ---\n",
        "# \n",
        "df.drop([\"height\", \"weight\"], axis = 1, inplace = True) \n",
        "\n",
        "# And preview our resulting dataset \n",
        "# --- \n",
        "# \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NKkADApG7PQ-"
      },
      "source": [
        "##### <font color=\"blue\">Example 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-TlGDqmxO20t",
        "colab": {}
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# We can also fix in-record & cross-datasets errors. \n",
        "# These kinds errors result from having two or more values in the same row \n",
        "# or across datasets contradicting with each other.\n",
        "# ---\n",
        "# Dataset = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "df['total_account_2'] = df['account_a'] + df['account_b']\n",
        "\n",
        "# Previewing our resulting dataframe \n",
        "# ---\n",
        "#\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf0W-6fnvx0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create another column to tell us whether if the two columns match.\n",
        "# We will use the numpy library through use of np.\n",
        "# ---\n",
        "# \n",
        "df['total_account?'] = np.where(df['total_account'] == df['total_account_2'], 'True', 'False')\n",
        "\n",
        "# Previewing our resulting dataframe \n",
        "# ---\n",
        "# \n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGxUgJJ4wilM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now select the records which don't match \n",
        "# ---\n",
        "# \n",
        "df.loc[df['total_account?'] == \"False\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CeKrayqxQuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# At this point we can do several things\n",
        "# 1. Correct the values,\n",
        "# 2. Drop/Delete the values,\n",
        "# 3. Or even decide to leave them as they are for certain reasons\n",
        "# ---\n",
        "# If we had a large dataset, we could get the no. of records using len(),\n",
        "# this would help us in our decision making process.\n",
        "# ---\n",
        "# \n",
        "len(df.loc[df['total_account?'] == \"False\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XXsiMoefO21J"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "18qYASsPO21L",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: While perfoming some analysis to answer a research question, \n",
        "# we realize that we don't need the team and weight columns in our dataset. \n",
        "# Let's drop those two columns below\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/NBABasketballDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En40GlHQ_41s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Previewing our dataset\n",
        "# ---\n",
        "#\n",
        "nba_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoY7VGO5AAs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping those two columns\n",
        "# ---\n",
        "#\n",
        "nba_df.drop([\"Height\", \"Weight\"], axis = 1, inplace = True) \n",
        "nba_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NLCP2GgOO21R",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Check for in-record and cross-dataset errors given the following dataset\n",
        "# Hint: \n",
        "# -> Perform other data cleaning techniques that you have learned so far for ease of working.\n",
        "# -> Total_Budget_Supported__by_Donors_KES = Total_-_Loan_Budget_Est_KES + Total_-_Grant_Budget_Est_KES\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/GVProjectsFundingDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WShoawVVAB9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our dataset\n",
        "# ---\n",
        "# \n",
        "gv_df2 = pd.read_csv('http://bit.ly/GVProjectsFundingDataset')\n",
        "gv_df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_xu_eWHAE07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Renaming our columns\n",
        "# ---\n",
        "# \n",
        "gv_df2.columns = gv_df2.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('_-', '_').str.replace('__', '_').str.replace('(', '').str.replace(')', '')\n",
        "gv_df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TihfNTnUAIMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking for in dataset errors\n",
        "# ---\n",
        "# \n",
        "gv_df2['total_budget_supported_by_donors_kes_2'] = gv_df2['total_loan_budget_est_kes'] + gv_df2['total_grant_budget_est_kes']\n",
        "\n",
        "# Previewing our resulting dataset \n",
        "# ---\n",
        "#\n",
        "gv_df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOkNNDFWAJ8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating another column to tell us whether if the two columns match\n",
        "# ---\n",
        "# \n",
        "gv_df2['total_budget_supported_by_donors_kes_2?'] = np.where(gv_df2['total_budget_supported_by_donors_kes_2'] == gv_df2['total_budget_supported_by_donors_kes'], 'True', 'False')\n",
        "\n",
        "# Previewing our resulting dataset \n",
        "# ---\n",
        "# \n",
        "gv_df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6iIqvw3ALv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's now select the records which don't match \n",
        "# ---\n",
        "# \n",
        "gv_df2.loc[gv_df2['total_budget_supported_by_donors_kes_2?'] == \"False\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31JTRvADANyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# At this point we can do several things\n",
        "# -> Correct the values,\n",
        "# -> Drop/Delete the values,\n",
        "# -> Or even decide to leave them as they are for certain reasons\n",
        "# ---\n",
        "# How many are these records?\n",
        "# ---\n",
        "# \n",
        "len(df.loc[df['total_account?'] == \"False\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UQvS83K_PBJh"
      },
      "source": [
        "## 4. Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CjklXwZLPBJw"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o8VZ3JLQPBJy"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dTlrpqh-PBJ5",
        "colab": {}
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# Finding duplicate records\n",
        "# -> Duplicate records are repeated records in a dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/NBABasketballDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "df = pd.read('http://bit.ly/NBABasketballDataset')\n",
        " \n",
        "# Again, we first explore our dataset by determining the shape of \n",
        "# our dataset (records/instances, columns/variables)\n",
        "# ---\n",
        "# \n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRdHqs9p1L8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can then identify which observations are duplicates\n",
        "# through the duplicated() function and sum() to know how many\n",
        "# duplicate records there are.\n",
        "# Normally, duplicate records are dropped from the dataset.\n",
        "# But in our case we don't have any duplicate records.\n",
        "# ---\n",
        "#\n",
        "df = df[~df.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd6R2AB77A1e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the no. of duplicates\n",
        "# ---\n",
        "# \n",
        "sum(df.duplicated())  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SV883_Ft7M4c"
      },
      "source": [
        "##### <font color=\"blue\">Example 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jFMDOQUCPBKg",
        "colab": {}
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Dropping duplicate columns\n",
        "# ---\n",
        "# Dataset = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n",
        "\n",
        "# In our previous dataset, if there were duplicates we\n",
        "# could have dropped the through the use of the drop_duplicates() function \n",
        "# as shown in this example \n",
        "# ---\n",
        "# \n",
        "df_duplicates = df.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8Hd0kybN7KEK"
      },
      "source": [
        "##### <font color=\"blue\">Example 3</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1CNl8VL-PBKp",
        "colab": {}
      },
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Dropping duplicates in a specific column\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "#\n",
        "\n",
        "# We can also consider records with repeated variables/columns \n",
        "# as duplicates and deal with them. For example, we can \n",
        "# identify duplicates in our dataset based on country.\n",
        "# ---\n",
        "#  \n",
        "duplicates_df = df[df.duplicated(['country'])] \n",
        "duplicates_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D33CBMxu5agd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Then dropping the duplicates as shown below.\n",
        "# NB: We will create in a new dataframe object which will contain our unique dataframe\n",
        "# which won't have any duplicates.\n",
        "# --- \n",
        "# \n",
        "unique_df = df.drop_duplicates(['country'])\n",
        "\n",
        "# Determining the size of our new dataset \n",
        "# We note that the two records were dropped from our original dataset\n",
        "# ---\n",
        "# \n",
        "unique_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qP7c_QZcPBK0"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1qxMH94BPBK4",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Find duplicates in the following dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/StaffDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjXuY9lsAZnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Previewing head\n",
        "# ---\n",
        "#\n",
        "staff_df = pd.read_csv('http://bit.ly/StaffDataset')\n",
        "staff_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vy-TSOB7AdTM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determining the shape of our dataset\n",
        "# ---\n",
        "# \n",
        "staff_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA1vUY4bAe2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the duplicates\n",
        "# ---\n",
        "# \n",
        "staff_df[staff_df.duplicated()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LYA6sECAgmd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the number of duplicate records\n",
        "# ---\n",
        "# \n",
        "sum(staff_df.duplicated())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vudHxVsePBLA"
      },
      "source": [
        "##### <font color=\"green\">Challenge 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ln3Js0AFPBLC",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Dealing with duplicates in the given dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/StaffDataset.\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIwAiK-eAm1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping the duplicates as shown below.\n",
        "# NB: We will save them in a new dataframe object which will contain our unique dataframe\n",
        "# --- \n",
        "#  \n",
        "staff_df.drop_duplicates()\n",
        "\n",
        "# Determining the size of our new dataset \n",
        "# We note that the two records were dropped from our original dataset\n",
        "# ---\n",
        "# \n",
        "staff_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_7MfKNGePLVE"
      },
      "source": [
        "## 5. Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tSyyvcJJPLVO"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gWiBc-smPLVS"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jz2zjwTZPLVT",
        "colab": {}
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# Finding records with missing data\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7c5CQH4A3pC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can check if there is any missing values in the entire dataframe as shown \n",
        "# NB: This method may not be the most convenient. Why?\n",
        "# ---\n",
        "# \n",
        "df.isnull()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZtDFohkKVab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also check for missing values in each column \n",
        "# NB: This method may not be the most convenient. Why?\n",
        "# Let's uncomment the following line\n",
        "# ---\n",
        "# \n",
        "df.isnull().any()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY9LaH8_KcKl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can check how many missing values there are across each variable/column by \n",
        "# ---\n",
        "# \n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3RTlthxKgbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also check to see if we have any missing values in the dataframe by \n",
        "# ---\n",
        "# \n",
        "df.isnull().values.any()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z3SDJZsKjz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lastly, We can also get a total count of missing values by \n",
        "#\n",
        "# ---\n",
        "df.isnull().sum().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B_mlBg-TPLVe"
      },
      "source": [
        "##### <font color=\"blue\">Example 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QuNTnbSmPLVf",
        "colab": {}
      },
      "source": [
        "# Example 2\n",
        "# ---\n",
        "# Dealing with the missing data\n",
        "# ---\n",
        "# \n",
        "\n",
        "# We can drop rows where all cells in that row is NA\n",
        "# Let's uncomment the following line\n",
        "# NB: We don't have these rows in our dataset \n",
        "# ---\n",
        "#\n",
        "df_cleaned = df.dropna(how='all')\n",
        "df_cleaned"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OWqJ6FJFmgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also drop columns if they only contain missing values\n",
        "# NB: We don't have these rows in our dataset \n",
        "# ---\n",
        "# \n",
        "df_without_columns = df.dropna(axis=1, how='all')\n",
        "df_without_columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT4fmeWyFtYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can drop rows that contain less than five observations\n",
        "# NB: We don't have these rows in our dataset \n",
        "# ---\n",
        "# \n",
        "df.dropna(thresh=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfgdzPzNF35d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lastly, we can also drop the missing observations\n",
        "# Let's uncomment the following two lines\n",
        "# ---\n",
        "#\n",
        "df_no_missing = df.dropna()\n",
        "df_no_missing\n",
        "\n",
        "\n",
        "# There are many methods of dealing with missing data however, \n",
        "# we only dealt with the above basic ones due to time constraints."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2aaKxkwk7GGN"
      },
      "source": [
        "##### <font color=\"blue\">Example 3</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dJf7iOj8rQrF",
        "colab": {}
      },
      "source": [
        "# Example 3\n",
        "# ---\n",
        "# Flag missing values\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# \n",
        "\n",
        "# We can also fill in missing data with zeros as shown.\n",
        "# NB: We will create a copy of the original dataframe\n",
        "# Let's uncomment the following line \n",
        "# ---\n",
        "# \n",
        "df2 = df.copy()\n",
        "df3 = df2.fillna(0)\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vbVkgj0VPLWh"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d_xipHWePLWj",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Find missing values in the following dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DCTitanicDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN1KqwZsApMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking how many missing values there are across each variable\n",
        "# ---\n",
        "# \n",
        "titanic_df = pd.read_csv('http://bit.ly/DCTitanicDataset')\n",
        "titanic_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVWzc9oIAo-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determining the size of our dataset\n",
        "# ---\n",
        "#\n",
        "titanic_df.shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLbiq55EAt2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking how many missing values there are across each variable\n",
        "# ---\n",
        "# \n",
        "titanic_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kKoKAw8HPLWo",
        "colab": {}
      },
      "source": [
        "# Challenge 2\n",
        "# ---\n",
        "# Question: Drop the variables with more than 500 missing values.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DCTitanicDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70qQcnqJAv1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can decide to drop the variables many missing values\n",
        "# ---\n",
        "# \n",
        "titanic_df.drop([\"cabin\", \"boat\", \"body\", \"home.dest\"], axis = 1, inplace = True) \n",
        "\n",
        "# Checking how many missing values there are across each variable\n",
        "# ---\n",
        "# \n",
        "titanic_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "v5M3iGK8PZ3Y"
      },
      "source": [
        "## 6. Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jnxNSUhdPZ3u"
      },
      "source": [
        "#### <font color=\"blue\">Examples</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0Z92GZUgPZ35"
      },
      "source": [
        "##### <font color=\"blue\">Example 1</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NzpMrSX1PZ36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8b64a6a5-d4ca-4565-9d17-4adbdc870d51"
      },
      "source": [
        "# Example 1\n",
        "# --- \n",
        "# Given the following dataset, find and deal with outliers.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/CountryDataset1\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "#  \n",
        "\n",
        "# Let's read data from url as dataframe\n",
        "# \n",
        "outliersc_df = pd.read_csv(\"http://bit.ly/CountryDataset1\") \n",
        "\n",
        "# Lets preview our our dataframe below\n",
        "#\n",
        "outliersc_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>year</th>\n",
              "      <th>pop</th>\n",
              "      <th>continent</th>\n",
              "      <th>lifeExp</th>\n",
              "      <th>gdpPercap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>1952</td>\n",
              "      <td>8425333.0</td>\n",
              "      <td>Asia</td>\n",
              "      <td>28.801</td>\n",
              "      <td>779.445314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>1957</td>\n",
              "      <td>9240934.0</td>\n",
              "      <td>Asia</td>\n",
              "      <td>30.332</td>\n",
              "      <td>820.853030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>1962</td>\n",
              "      <td>10267083.0</td>\n",
              "      <td>Asia</td>\n",
              "      <td>31.997</td>\n",
              "      <td>853.100710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>1967</td>\n",
              "      <td>11537966.0</td>\n",
              "      <td>Asia</td>\n",
              "      <td>34.020</td>\n",
              "      <td>836.197138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Afghanistan</td>\n",
              "      <td>1972</td>\n",
              "      <td>13079460.0</td>\n",
              "      <td>Asia</td>\n",
              "      <td>36.088</td>\n",
              "      <td>739.981106</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       country  year         pop continent  lifeExp   gdpPercap\n",
              "0  Afghanistan  1952   8425333.0      Asia   28.801  779.445314\n",
              "1  Afghanistan  1957   9240934.0      Asia   30.332  820.853030\n",
              "2  Afghanistan  1962  10267083.0      Asia   31.997  853.100710\n",
              "3  Afghanistan  1967  11537966.0      Asia   34.020  836.197138\n",
              "4  Afghanistan  1972  13079460.0      Asia   36.088  739.981106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MtbaxstdIby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d9c189e-155a-4870-c940-221ac7181e86"
      },
      "source": [
        "# Checking the size of our dataset for cleaning purposes\n",
        "# ---\n",
        "#\n",
        "outliersc_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1704, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q33K99Jsc1wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# There are many ways of dealing with the outliers however in this session we wiil \n",
        "# use the interquartile range (IQR). \n",
        "# The IQR is the first quartile subtracted from the third quartile, \n",
        "# i.e. the range covered by the middle 50% of the data. Values outside this range\n",
        "# will be considered as outliers. If we were to use a box plot visualisation then,\n",
        "# we would be able to visually see those values outside this range. \n",
        "# Something to note is that this method will consider only the numerical values in \n",
        "# our dataset. Lets now calculate the IQR for each column.\n",
        "# ---\n",
        "#\n",
        "\n",
        "# We first defining our quantiles using the quantile() function\n",
        "# ---\n",
        "# \n",
        "Q1 = outliersc_df.quantile(0.25)\n",
        "Q3 = outliersc_df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "IQR\n",
        "\n",
        "# Then filtering out now filter out outliers by getting values which are outside our IQR Range.\n",
        "# ---\n",
        "#\n",
        "outliers_df_iqr = outliersc_df[((outliersc_df < (Q1 - 1.5 * IQR)) | (outliersc_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Checking the size of the dataset with outliers for cleaning purposes\n",
        "# ---\n",
        "#\n",
        "outliers_df_iqr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWJth6qXczMC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can also explore our outliers by doing the following\n",
        "# ---\n",
        "# \n",
        "outliersc_df_iqr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjGji1pYUMTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lastly, the most common method of handling our outliers is to drop them.\n",
        "# In some cases we can:\n",
        "# 1. Leave them if they are genuine\n",
        "# 2. Replace them with values within the IQR range\n",
        "# 3. Drop them\n",
        "# ---\n",
        "# In our case, we will drop them.\n",
        "# We just use the \"~\" character to refer to the other part of the dataset that \n",
        "# does not have outliers\n",
        "# ---\n",
        "# \n",
        "clean_dfc_iqr = outliersc_df[ ~((outliersc_df < (Q1 - 1.5 * IQR)) | (outliersc_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "\n",
        "# Checking the size of our final dataset.\n",
        "clean_dfc_iqr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wt8Se1hXPZ4C"
      },
      "source": [
        "#### <font color=\"green\">Challenges</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hwsxAgwLPZ4Y",
        "colab": {}
      },
      "source": [
        "# Challenge 1\n",
        "# ---\n",
        "# Question: Find and Deal with the outliers in the given dataset.\n",
        "# ---\n",
        "# Dataset url = http://bit.ly/DataCleaningDataset\n",
        "# ---\n",
        "# OUR CODE GOES BELOW\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-2vNzL7A8fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our dataset for outlier detection\n",
        "# ---\n",
        "# \n",
        "outlier_df = pd.read_csv('http://bit.ly/DataCleaningDataset', ';')\n",
        "outlier_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSErnG_sA9Z3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding the shape of our dataset\n",
        "# ---\n",
        "# \n",
        "outlier_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcrHltKlBArW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining our quantiles\n",
        "# ---\n",
        "# \n",
        "Q1 = outlier_df.quantile(0.25)\n",
        "Q3 = outlier_df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "IQR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7w0HsBUBEaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Determining how many outliers there are in our dataset\n",
        "# ---\n",
        "# \n",
        "outlier_df_iqr = outlier_df[((outlier_df < (Q1 - 1.5 * IQR)) |(outlier_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "outlier_df_iqr.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUreKyHdBG6h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displaying our outliers\n",
        "# ---\n",
        "# \n",
        "outlier_df[((outlier_df < (Q1 - 1.5 * IQR)) |(outlier_df > (Q3 + 1.5 * IQR))).any(axis=1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pgeff9WGBH1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropping the outliers\n",
        "# ---\n",
        "# \n",
        "clean_df = outlier_df[~((outlier_df < (Q1 - 1.5 * IQR)) |(outlier_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "clean_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBAxBxedBJnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Displaying our clean dataset\n",
        "# NB: Our dataset still needs to be cleaned in other ways...\n",
        "# ---\n",
        "# \n",
        "clean_df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}